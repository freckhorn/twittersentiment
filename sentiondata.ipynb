{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fri May 08 03:00:51 +0000 2015', 'Fri May 08 03:46:33 +0000 2015', 'Fri May 08 04:13:10 +0000 2015', 'Sat May 09 06:54:03 +0000 2015', 'Sat May 09 14:59:18 +0000 2015']\n"
     ]
    }
   ],
   "source": [
    "import pickle as p\n",
    "\n",
    "\n",
    "d = p.load( open( \"tesla5853.p\", \"rb\" ) )\n",
    "\n",
    "date = []\n",
    "\n",
    "counter=0\n",
    "for i in range(5):\n",
    "    counter += 1\n",
    "    date.append(d[i]['date'])\n",
    "print(date)\n",
    "    \n",
    "import pandas as pd\n",
    "# lst1 = d[]\n",
    "# lst2 = range(100)\n",
    "# lst3 = range(100)\n",
    "# percentile_list = pd.DataFrame(\n",
    "#     {'lst1Title': lst1,\n",
    "#      'lst2Title': lst2,\n",
    "#      'lst3Title': lst3\n",
    "#     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    tw = {'ind':0, 'txt': str(), 'date': None, 'pos': int, 'neg': int, 'neut': int}\n",
    "    tw['ind'] = d[i]['ind']\n",
    "    tw['txt'] = d[i]['txt']\n",
    "    tw['date'] = d[i]['date']\n",
    "    tw[''] = \n",
    "    print(tw)\n",
    "    output.append(tw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date,Open,High,Low,Close,Adj Close,Volume\n",
      "\n",
      "2015-09-28\n",
      "2015-05-26\n",
      "2015-05-27\n",
      "2015-05-28\n",
      "2015-05-29\n",
      "2015-06-01\n",
      "2015-06-02\n",
      "2015-06-03\n",
      "2015-06-04\n",
      "2015-06-05\n",
      "2015-06-08\n",
      "2015-06-09\n",
      "2015-06-10\n",
      "2015-06-11\n",
      "2015-06-12\n",
      "2015-06-15\n",
      "2015-06-16\n",
      "2015-06-17\n",
      "2015-06-18\n",
      "2015-06-19\n",
      "2015-06-22\n",
      "2015-06-23\n",
      "2015-06-24\n",
      "2015-06-25\n",
      "2015-06-26\n",
      "2015-06-29\n",
      "2015-06-30\n",
      "2015-07-01\n",
      "2015-07-02\n",
      "2015-07-06\n",
      "2015-07-07\n",
      "2015-07-08\n",
      "2015-07-09\n",
      "2015-07-10\n",
      "2015-07-13\n",
      "2015-07-14\n",
      "2015-07-15\n",
      "2015-07-16\n",
      "2015-07-17\n",
      "2015-07-20\n",
      "2015-07-21\n",
      "2015-07-22\n",
      "2015-07-23\n",
      "2015-07-24\n",
      "2015-07-27\n",
      "2015-07-28\n",
      "2015-07-29\n",
      "2015-07-30\n",
      "2015-07-31\n",
      "2015-08-03\n",
      "2015-08-04\n",
      "2015-08-05\n",
      "2015-08-06\n",
      "2015-08-07\n",
      "2015-08-10\n",
      "2015-08-11\n",
      "2015-08-12\n",
      "2015-08-13\n",
      "2015-08-14\n",
      "2015-08-17\n",
      "2015-08-18\n",
      "2015-08-19\n",
      "2015-08-20\n",
      "2015-08-21\n",
      "2015-08-24\n",
      "2015-08-25\n",
      "2015-08-26\n",
      "2015-08-27\n",
      "2015-08-28\n",
      "2015-08-31\n",
      "2015-09-01\n",
      "2015-09-02\n",
      "2015-09-03\n",
      "2015-09-04\n",
      "2015-09-08\n",
      "2015-09-09\n",
      "2015-09-10\n",
      "2015-09-11\n",
      "2015-09-14\n",
      "2015-09-15\n",
      "2015-09-16\n",
      "2015-09-17\n",
      "2015-09-18\n",
      "2015-09-21\n",
      "2015-09-22\n",
      "2015-09-23\n",
      "2015-09-24\n",
      "2015-09-25\n"
     ]
    }
   ],
   "source": [
    "vol = []\n",
    "peak = []\n",
    "with open('TSLA.csv') as csvfile:\n",
    "    print(csvfile.readline())\n",
    "    \n",
    "    while True:\n",
    "        csv = csvfile.readline()\n",
    "        if(len(csv) < 1):\n",
    "           break\n",
    "        else:\n",
    "            print(line[0])\n",
    "            line = csv.split(',')\n",
    "            vol.append(float(line[6]))\n",
    "            peak.append(float(line[2])-float(line[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date,Open,High,Low,Close,Adj Close,Volume\n",
      "\n",
      "2015-09-28\n",
      "2015-05-26\n",
      "2015-05-27\n",
      "2015-05-28\n",
      "2015-05-29\n",
      "2015-06-01\n",
      "2015-06-02\n",
      "2015-06-03\n",
      "2015-06-04\n",
      "2015-06-05\n",
      "2015-06-08\n",
      "2015-06-09\n",
      "2015-06-10\n",
      "2015-06-11\n",
      "2015-06-12\n",
      "2015-06-15\n",
      "2015-06-16\n",
      "2015-06-17\n",
      "2015-06-18\n",
      "2015-06-19\n",
      "2015-06-22\n",
      "2015-06-23\n",
      "2015-06-24\n",
      "2015-06-25\n",
      "2015-06-26\n",
      "2015-06-29\n",
      "2015-06-30\n",
      "2015-07-01\n",
      "2015-07-02\n",
      "2015-07-06\n",
      "2015-07-07\n",
      "2015-07-08\n",
      "2015-07-09\n",
      "2015-07-10\n",
      "2015-07-13\n",
      "2015-07-14\n",
      "2015-07-15\n",
      "2015-07-16\n",
      "2015-07-17\n",
      "2015-07-20\n",
      "2015-07-21\n",
      "2015-07-22\n",
      "2015-07-23\n",
      "2015-07-24\n",
      "2015-07-27\n",
      "2015-07-28\n",
      "2015-07-29\n",
      "2015-07-30\n",
      "2015-07-31\n",
      "2015-08-03\n",
      "2015-08-04\n",
      "2015-08-05\n",
      "2015-08-06\n",
      "2015-08-07\n",
      "2015-08-10\n",
      "2015-08-11\n",
      "2015-08-12\n",
      "2015-08-13\n",
      "2015-08-14\n",
      "2015-08-17\n",
      "2015-08-18\n",
      "2015-08-19\n",
      "2015-08-20\n",
      "2015-08-21\n",
      "2015-08-24\n",
      "2015-08-25\n",
      "2015-08-26\n",
      "2015-08-27\n",
      "2015-08-28\n",
      "2015-08-31\n",
      "2015-09-01\n",
      "2015-09-02\n",
      "2015-09-03\n",
      "2015-09-04\n",
      "2015-09-08\n",
      "2015-09-09\n",
      "2015-09-10\n",
      "2015-09-11\n",
      "2015-09-14\n",
      "2015-09-15\n",
      "2015-09-16\n",
      "2015-09-17\n",
      "2015-09-18\n",
      "2015-09-21\n",
      "2015-09-22\n",
      "2015-09-23\n",
      "2015-09-24\n",
      "2015-09-25\n"
     ]
    }
   ],
   "source": [
    "import pickle as p\n",
    "import re\n",
    "from textblob import TextBlob \n",
    "\n",
    "d = p.load( open( \"tes_data.p\", \"rb\" ) )\n",
    "\n",
    "\n",
    "vol = []\n",
    "peak = []\n",
    "with open('TSLA.csv') as csvfile:\n",
    "    print(csvfile.readline())\n",
    "    \n",
    "    while True:\n",
    "        csv = csvfile.readline()\n",
    "        if(len(csv) < 1):\n",
    "           break\n",
    "        else:\n",
    "            print(line[0])\n",
    "            line = csv.split(',')\n",
    "            vol.append(float(line[6]))\n",
    "            peak.append(float(line[2])-float(line[1]))\n",
    "\n",
    "def clean_tweet(tweet): \n",
    "    ''' \n",
    "    Utility function to clean tweet text by removing links, special characters \n",
    "    using simple regex statements. \n",
    "    '''\n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split()) \n",
    "    \n",
    "def get_tweet_sentiment(tweet): \n",
    "    ''' \n",
    "    Utility function to classify sentiment of passed tweet \n",
    "    using textblob's sentiment method \n",
    "    '''\n",
    "    # create TextBlob object of passed tweet text \n",
    "    analysis = TextBlob(clean_tweet(tweet)) \n",
    "    # set sentiment \n",
    "    if analysis.sentiment.polarity > 0: \n",
    "        return 'positive'\n",
    "    elif analysis.sentiment.polarity == 0: \n",
    "        return 'neutral'\n",
    "    else: \n",
    "        return 'negative'\n",
    "    \n",
    "sentiment = []\n",
    "for i in range(len(d)):\n",
    "#     print(d[i])\n",
    "#     print(get_tweet_sentiment(clean_tweet(tweet['txt'])))\n",
    "    tw = {'ind':0, 'date': None, 'sent': int}\n",
    "    if(get_tweet_sentiment(clean_tweet(d[i]['txt'])) == 'negative'):\n",
    "        tw['sent'] = -1\n",
    "    if(get_tweet_sentiment(clean_tweet(d[i]['txt'])) == 'positive'):\n",
    "        tw['sent'] = 1\n",
    "    if(get_tweet_sentiment(clean_tweet(d[i]['txt'])) == 'neutral'):\n",
    "        tw['sent'] = 0\n",
    "    tw['ind'] = d[i]['ind']\n",
    "#     tw['txt'] = d[i]['txt']\n",
    "    tw['date'] = d[i]['date']\n",
    "\n",
    "    sentiment.append(tw)\n",
    "#     print(tw)\n",
    "\n",
    "sentif = []\n",
    "# for i in range(len(sentiment)):\n",
    "#     if(sentiment[i]['date'] ==sentiment[i+1]['date'] ):\n",
    "        \n",
    "\n",
    "import csv\n",
    "lines = []\n",
    "filtered = []\n",
    "counter = 0\n",
    "\n",
    "\n",
    "\n",
    "with open('TSLA.csv') as csvfile:\n",
    "    readCSV = csv.reader(csvfile, delimiter=',')\n",
    "    for row in readCSV:\n",
    "        if(counter == 0):\n",
    "            row = []\n",
    "            row.append('Date')\n",
    "            row.append('Sent')\n",
    "            row.append('Vol')\n",
    "            row.append('Peak')\n",
    "            row.append('1 Day')\n",
    "            lines.append(row)\n",
    "        else:\n",
    "#             print(row)\n",
    "            if float(row[1])-float(row[4]) < 0:\n",
    "                change = 'neg'\n",
    "            else:\n",
    "                change = 'pos'\n",
    "            temp = row[0]\n",
    "            row = []\n",
    "            \n",
    "            row.append(temp)\n",
    "            row.append(sentiment[counter]['sent'])\n",
    "            row.append(vol[counter-1])\n",
    "            row.append(peak[counter-1])\n",
    "            row.append(change)\n",
    "            lines.append(row)\n",
    "        counter+=1\n",
    "        \n",
    "with open('test.csv', 'w') as writeFile:\n",
    "    writer = csv.writer(writeFile)\n",
    "    writer.writerows(lines)\n",
    "\n",
    "\n",
    "writeFile.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6901408450704225"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "data = pd.read_csv('test.csv', header = 'infer')\n",
    "\n",
    "\n",
    "# data\n",
    "\n",
    "\n",
    "y = data['1 Day']\n",
    "x = data.drop('1 Day', axis = 1)\n",
    "x =x.drop('Date',axis=1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.8, random_state=1)\n",
    "\n",
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, y_pred)\n",
    "\n",
    "# import pydotplus\n",
    "# dot_data = tree.export_graphviz(clf, out_file=None)\n",
    "# graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "# graph.write_pdf('diabetes.pdf')\n",
    "\n",
    "# from IPython.display import Image\n",
    "# Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import tweepy \n",
    "from tweepy import OAuthHandler \n",
    "from textblob import TextBlob \n",
    "\n",
    "class TwitterClient(object): \n",
    "\t''' \n",
    "\tGeneric Twitter Class for sentiment analysis. \n",
    "\t'''\n",
    "\tdef __init__(self): \n",
    "\t\t''' \n",
    "\t\tClass constructor or initialization method. \n",
    "\t\t'''\n",
    "\t\t# keys and tokens from the Twitter Dev Console \n",
    "\t\tconsumer_key = 'SFIkwbCxha8I6Uu8wUIs3k9Lo'\n",
    "\t\tconsumer_secret = 'bEWqchDzDJJWy9k5Rma85PHFK3I8nxqZbMxe5RGEgK2gxcvH7I'\n",
    "\t\taccess_token = '1357970215-vaTMuQqIPnVcK8Up4EnKL1YsTTDtdc4VpSKR4Ic'\n",
    "\t\taccess_token_secret = 'LJABo7OJ5aXotypTKYUqh9VeC0yI70tD4t6VNN9BSvgAC'\n",
    "\n",
    "#         C_KEY = 'SFIkwbCxha8I6Uu8wUIs3k9Lo'\n",
    "# C_SECRET = 'bEWqchDzDJJWy9k5Rma85PHFK3I8nxqZbMxe5RGEgK2gxcvH7I'\n",
    "# A_TOKEN_KEY = '1357970215-vaTMuQqIPnVcK8Up4EnKL1YsTTDtdc4VpSKR4Ic'\n",
    "# A_TOKEN_SECRET = 'LJABo7OJ5aXotypTKYUqh9VeC0yI70tD4t6VNN9BSvgAC'\n",
    "        # attempt authentication \n",
    "\t\ttry: \n",
    "\t\t\t# create OAuthHandler object \n",
    "\t\t\tself.auth = OAuthHandler(consumer_key, consumer_secret) \n",
    "\t\t\t# set access token and secret \n",
    "\t\t\tself.auth.set_access_token(access_token, access_token_secret) \n",
    "\t\t\t# create tweepy API object to fetch tweets \n",
    "\t\t\tself.api = tweepy.API(self.auth) \n",
    "\t\texcept: \n",
    "\t\t\tprint(\"Error: Authentication Failed\") \n",
    "\n",
    "\tdef clean_tweet(self, tweet): \n",
    "\t\t''' \n",
    "\t\tUtility function to clean tweet text by removing links, special characters \n",
    "\t\tusing simple regex statements. \n",
    "\t\t'''\n",
    "\t\treturn ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split()) \n",
    "\n",
    "\tdef get_tweet_sentiment(self, tweet): \n",
    "\t\t''' \n",
    "\t\tUtility function to classify sentiment of passed tweet \n",
    "\t\tusing textblob's sentiment method \n",
    "\t\t'''\n",
    "\t\t# create TextBlob object of passed tweet text \n",
    "\t\tanalysis = TextBlob(self.clean_tweet(tweet)) \n",
    "\t\t# set sentiment \n",
    "\t\tif analysis.sentiment.polarity > 0: \n",
    "\t\t\treturn 'positive'\n",
    "\t\telif analysis.sentiment.polarity == 0: \n",
    "\t\t\treturn 'neutral'\n",
    "\t\telse: \n",
    "\t\t\treturn 'negative'\n",
    "\n",
    "\tdef get_tweets(self, query, count = 10): \n",
    "\t\t''' \n",
    "\t\tMain function to fetch tweets and parse them. \n",
    "\t\t'''\n",
    "\t\t# empty list to store parsed tweets \n",
    "\t\ttweets = [] \n",
    "\n",
    "\t\ttry: \n",
    "\t\t\t# call twitter api to fetch tweets \n",
    "\t\t\tfetched_tweets = self.api.search(q = query, count = count) \n",
    "\n",
    "\t\t\t# parsing tweets one by one \n",
    "\t\t\tfor tweet in fetched_tweets: \n",
    "\t\t\t\t# empty dictionary to store required params of a tweet \n",
    "\t\t\t\tparsed_tweet = {} \n",
    "\n",
    "\t\t\t\t# saving text of tweet \n",
    "\t\t\t\tparsed_tweet['text'] = tweet.text \n",
    "\t\t\t\t# saving sentiment of tweet \n",
    "\t\t\t\tparsed_tweet['sentiment'] = self.get_tweet_sentiment(tweet.text) \n",
    "\n",
    "\t\t\t\t# appending parsed tweet to tweets list \n",
    "\t\t\t\tif tweet.retweet_count > 0: \n",
    "\t\t\t\t\t# if tweet has retweets, ensure that it is appended only once \n",
    "\t\t\t\t\tif parsed_tweet not in tweets: \n",
    "\t\t\t\t\t\ttweets.append(parsed_tweet) \n",
    "\t\t\t\telse: \n",
    "\t\t\t\t\ttweets.append(parsed_tweet) \n",
    "\n",
    "\t\t\t# return parsed tweets \n",
    "\t\t\treturn tweets \n",
    "\n",
    "\t\texcept tweepy.TweepError as e: \n",
    "\t\t\t# print error (if any) \n",
    "\t\t\tprint(\"Error : \" + str(e)) \n",
    "\n",
    "def main(): \n",
    "\t# creating object of TwitterClient Class \n",
    "\tapi = TwitterClient() \n",
    "\t# calling function to get tweets \n",
    "\ttweets = api.get_tweets(query = 'tesla', count = 1000) \n",
    "\n",
    "\t# picking positive tweets from tweets \n",
    "\tptweets = [tweet for tweet in tweets if tweet['sentiment'] == 'positive'] \n",
    "\t# percentage of positive tweets \n",
    "\tprint(\"Positive tweets percentage: {} %\".format(100*len(ptweets)/len(tweets))) \n",
    "\t# picking negative tweets from tweets \n",
    "\tntweets = [tweet for tweet in tweets if tweet['sentiment'] == 'negative'] \n",
    "\t# percentage of negative tweets \n",
    "\tprint(\"Negative tweets percentage: {} %\".format(100*len(ntweets)/len(tweets))) \n",
    "\t# percentage of neutral tweets \n",
    "# \tprint(\"Neutral tweets percentage: {} %\\ \".format(100*len(tweets - ntweets - ptweets)/len(tweets))) \n",
    "\n",
    "\t# printing first 5 positive tweets \n",
    "\tprint(\"\\n\\nPositive tweets:\") \n",
    "\tfor tweet in ptweets[:10]: \n",
    "\t\tprint(tweet['text']) \n",
    "\n",
    "\t# printing first 5 negative tweets \n",
    "\tprint(\"\\n\\nNegative tweets:\") \n",
    "\tfor tweet in ntweets[:10]: \n",
    "\t\tprint(tweet['text']) \n",
    "\n",
    "if __name__ == \"__main__\": \n",
    "    # calling main function \n",
    "    main() \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
